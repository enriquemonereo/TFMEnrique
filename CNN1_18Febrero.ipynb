{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "import optim\n",
    "from hyperopt.hp import choice\n",
    "from hyperopt.hp import uniform\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform#, conditional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Dropout,Flatten,Conv1D,MaxPooling1D,Input,Conv2D,MaxPooling2D,Reshape,SeparableConv1D,BatchNormalization\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam,sgd\n",
    "import keras.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam = keras.optimizers.Adam(lr=0.001,beta_1=0.9,beta_2=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargo datos y quito columna indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "caracteristicas=np.loadtxt('/../Users/kike/Desktop/Master/TFM/characteristics_todas.dat')\n",
    "labels=np.loadtxt('/../Users/kike/Desktop/Master/TFM/labels_todas.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels0=labels[0:5400,0]\n",
    "labels0=labels0.reshape(5400,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels0=labels[0:5400,0]\n",
    "labels0=labels0.reshape(5400,1,1)\n",
    "labels1=labels[0:5400,1]\n",
    "labels1=labels1.reshape(5400,1,1)\n",
    "labels2=labels[0:5400,2]\n",
    "labels2=labels2.reshape(5400,1,1)\n",
    "labels3=labels[0:5400,3]\n",
    "labels3=labels3.reshape(5400,1,1)\n",
    "labels4=labels[0:5400,4]\n",
    "labels4=labels4.reshape(5400,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "carac=caracteristicas[0:5400,1:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 12)\n"
     ]
    }
   ],
   "source": [
    "print(carac.shape)\n",
    "n_cols=carac.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=carac0.reshape(5400,1,1)\n",
    "#X.shape\n",
    "#Y=labels0.reshape(5400,1,1)\n",
    "#X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización y reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "mean=carac.mean(axis=0)\n",
    "carac -= mean\n",
    "std = carac.std(axis=0)\n",
    "carac /=std\n",
    "print(carac.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "meany=labels.mean(axis=0)\n",
    "labels -= meany\n",
    "stdy = labels.std(axis=0)\n",
    "labels /=stdy\n",
    "print(labels.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 1, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carac=carac.reshape(5400,1,12)\n",
    "labels=labels.reshape(5400,1,5)\n",
    "carac.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "carac=carac.reshape(40,135,12)\n",
    "labels=labels.reshape(40,135,5)\n",
    "labels0=labels0.reshape(40,135,1) \n",
    "labels1=labels1.reshape(40,135,1)\n",
    "labels2=labels2.reshape(40,135,1)\n",
    "labels3=labels3.reshape(40,135,1)\n",
    "labels4=labels4.reshape(40,135,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "carac=carac.reshape(5400,1,12)\n",
    "labels=labels.reshape(5400,1,5)\n",
    "labels0=labels0.reshape(5400,1,1)\n",
    "labels1=labels1.reshape(5400,1,1)\n",
    "labels2=labels2.reshape(5400,1,1)\n",
    "labels3=labels3.reshape(5400,1,1)\n",
    "labels4=labels4.reshape(5400,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam = keras.optimizers.Adam(lr=0.001,beta_1=0.9,beta_2=0.9)\n",
    "sgd=keras.optimizers.SGD(learning_rate=0.02, momentum=0.1, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3779 samples, validate on 1621 samples\n",
      "Epoch 1/10000\n",
      "3779/3779 [==============================] - 0s 112us/step - loss: 0.7414 - mse: 0.7414 - val_loss: 1.6189 - val_mse: 1.6189\n",
      "Epoch 2/10000\n",
      "3779/3779 [==============================] - 0s 66us/step - loss: 0.6635 - mse: 0.6635 - val_loss: 1.5921 - val_mse: 1.5921\n",
      "Epoch 3/10000\n",
      "3779/3779 [==============================] - 0s 76us/step - loss: 0.6484 - mse: 0.6484 - val_loss: 1.5863 - val_mse: 1.5863\n",
      "Epoch 4/10000\n",
      "3779/3779 [==============================] - 0s 63us/step - loss: 0.6446 - mse: 0.6446 - val_loss: 1.5863 - val_mse: 1.5863\n",
      "Epoch 5/10000\n",
      "3779/3779 [==============================] - 0s 65us/step - loss: 0.6434 - mse: 0.6434 - val_loss: 1.5863 - val_mse: 1.5863\n",
      "Epoch 6/10000\n",
      "3779/3779 [==============================] - 0s 83us/step - loss: 0.6430 - mse: 0.6430 - val_loss: 1.5880 - val_mse: 1.5880\n",
      "Epoch 7/10000\n",
      "3779/3779 [==============================] - 0s 75us/step - loss: 0.6428 - mse: 0.6428 - val_loss: 1.5854 - val_mse: 1.5854\n",
      "Epoch 8/10000\n",
      "3779/3779 [==============================] - 0s 73us/step - loss: 0.6428 - mse: 0.6428 - val_loss: 1.5866 - val_mse: 1.5866\n",
      "Epoch 9/10000\n",
      "3779/3779 [==============================] - 0s 57us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5872 - val_mse: 1.5872\n",
      "Epoch 10/10000\n",
      "3779/3779 [==============================] - 0s 78us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5891 - val_mse: 1.5891\n",
      "Epoch 11/10000\n",
      "3779/3779 [==============================] - 0s 78us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5907 - val_mse: 1.5907\n",
      "Epoch 12/10000\n",
      "3779/3779 [==============================] - 0s 73us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5893 - val_mse: 1.5893\n",
      "Epoch 13/10000\n",
      "3779/3779 [==============================] - 0s 68us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5881 - val_mse: 1.5881\n",
      "Epoch 14/10000\n",
      "3779/3779 [==============================] - 0s 47us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5876 - val_mse: 1.5876\n",
      "Epoch 15/10000\n",
      "3779/3779 [==============================] - 0s 56us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5860 - val_mse: 1.5860\n",
      "Epoch 16/10000\n",
      "3779/3779 [==============================] - 0s 81us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5859 - val_mse: 1.5859\n",
      "Epoch 17/10000\n",
      "3779/3779 [==============================] - 0s 82us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5862 - val_mse: 1.5862\n",
      "Epoch 18/10000\n",
      "3779/3779 [==============================] - 0s 40us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5861 - val_mse: 1.5861\n",
      "Epoch 19/10000\n",
      "3779/3779 [==============================] - 0s 78us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5851 - val_mse: 1.5851\n",
      "Epoch 20/10000\n",
      "3779/3779 [==============================] - 0s 49us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5840 - val_mse: 1.5840\n",
      "Epoch 21/10000\n",
      "3779/3779 [==============================] - 0s 40us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5850 - val_mse: 1.5850\n",
      "Epoch 22/10000\n",
      "3779/3779 [==============================] - 0s 39us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5868 - val_mse: 1.5868\n",
      "Epoch 23/10000\n",
      "3779/3779 [==============================] - 0s 40us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5863 - val_mse: 1.5863\n",
      "Epoch 24/10000\n",
      "3779/3779 [==============================] - 0s 40us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5862 - val_mse: 1.5862\n",
      "Epoch 25/10000\n",
      "3779/3779 [==============================] - 0s 43us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5847 - val_mse: 1.5847\n",
      "Epoch 26/10000\n",
      "3779/3779 [==============================] - 0s 45us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5863 - val_mse: 1.5863\n",
      "Epoch 27/10000\n",
      "3779/3779 [==============================] - 0s 79us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 1.5840 - val_mse: 1.5840\n",
      "Epoch 28/10000\n",
      "3779/3779 [==============================] - 0s 62us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5826 - val_mse: 1.5826\n",
      "Epoch 29/10000\n",
      "3779/3779 [==============================] - 0s 65us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 1.5827 - val_mse: 1.5827\n",
      "Epoch 30/10000\n",
      "3779/3779 [==============================] - 0s 51us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5859 - val_mse: 1.5859\n",
      "Epoch 31/10000\n",
      "3779/3779 [==============================] - 0s 60us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 1.5831 - val_mse: 1.5831\n",
      "Epoch 32/10000\n",
      "3779/3779 [==============================] - 0s 57us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5847 - val_mse: 1.5847\n",
      "Epoch 33/10000\n",
      "3779/3779 [==============================] - 0s 72us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5844 - val_mse: 1.5844\n",
      "Epoch 34/10000\n",
      "3779/3779 [==============================] - 0s 44us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5871 - val_mse: 1.5871\n",
      "Epoch 35/10000\n",
      "3779/3779 [==============================] - 0s 39us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5855 - val_mse: 1.5855\n",
      "Epoch 36/10000\n",
      "3779/3779 [==============================] - 0s 48us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5858 - val_mse: 1.5858\n",
      "Epoch 37/10000\n",
      "3779/3779 [==============================] - 0s 52us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5856 - val_mse: 1.5856\n",
      "Epoch 38/10000\n",
      "3779/3779 [==============================] - 0s 58us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5889 - val_mse: 1.5889\n",
      "Epoch 39/10000\n",
      "3779/3779 [==============================] - 0s 52us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5876 - val_mse: 1.5876\n",
      "Epoch 40/10000\n",
      "3779/3779 [==============================] - 0s 67us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5868 - val_mse: 1.5868\n",
      "Epoch 41/10000\n",
      "3779/3779 [==============================] - 0s 58us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5859 - val_mse: 1.5859\n",
      "Epoch 42/10000\n",
      "3779/3779 [==============================] - 0s 40us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5837 - val_mse: 1.5837\n",
      "Epoch 43/10000\n",
      "3779/3779 [==============================] - 0s 56us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5848 - val_mse: 1.5848\n",
      "Epoch 44/10000\n",
      "3779/3779 [==============================] - 0s 74us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 1.5813 - val_mse: 1.5813\n",
      "Epoch 45/10000\n",
      "3779/3779 [==============================] - 0s 44us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5846 - val_mse: 1.5846\n",
      "Epoch 46/10000\n",
      "3779/3779 [==============================] - 0s 43us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5874 - val_mse: 1.5874\n",
      "Epoch 47/10000\n",
      "3779/3779 [==============================] - 0s 66us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5860 - val_mse: 1.5860\n",
      "Epoch 48/10000\n",
      "3779/3779 [==============================] - 0s 66us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 1.5870 - val_mse: 1.5870\n",
      "Epoch 49/10000\n",
      "3779/3779 [==============================] - 0s 51us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5893 - val_mse: 1.5893\n",
      "Epoch 50/10000\n",
      "3779/3779 [==============================] - 0s 47us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5894 - val_mse: 1.5894\n",
      "Epoch 51/10000\n",
      "3779/3779 [==============================] - 0s 62us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5880 - val_mse: 1.5880\n",
      "Epoch 52/10000\n",
      "3779/3779 [==============================] - 0s 67us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5883 - val_mse: 1.5883\n",
      "Epoch 53/10000\n",
      "3779/3779 [==============================] - 0s 61us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5883 - val_mse: 1.5883\n",
      "Epoch 54/10000\n",
      "3779/3779 [==============================] - 0s 40us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5889 - val_mse: 1.5889\n",
      "Epoch 55/10000\n",
      "3779/3779 [==============================] - 0s 50us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5862 - val_mse: 1.5862\n",
      "Epoch 56/10000\n",
      "3779/3779 [==============================] - 0s 62us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5845 - val_mse: 1.5845\n",
      "Epoch 57/10000\n",
      "3779/3779 [==============================] - 0s 44us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5857 - val_mse: 1.5857\n",
      "Epoch 58/10000\n",
      "3779/3779 [==============================] - 0s 52us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5848 - val_mse: 1.5848\n",
      "Epoch 59/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3779/3779 [==============================] - 0s 63us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5850 - val_mse: 1.5850\n",
      "Epoch 60/10000\n",
      "3779/3779 [==============================] - 0s 52us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5860 - val_mse: 1.5860\n",
      "Epoch 61/10000\n",
      "3779/3779 [==============================] - 0s 44us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5856 - val_mse: 1.5856\n",
      "Epoch 62/10000\n",
      "3779/3779 [==============================] - 0s 47us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 1.5832 - val_mse: 1.5832\n",
      "Epoch 63/10000\n",
      "3779/3779 [==============================] - 0s 49us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5826 - val_mse: 1.5826\n",
      "Epoch 64/10000\n",
      "3779/3779 [==============================] - 0s 69us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 1.5862 - val_mse: 1.5862\n",
      "Epoch 65/10000\n",
      "3779/3779 [==============================] - 0s 60us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5859 - val_mse: 1.5859\n",
      "Epoch 66/10000\n",
      "3779/3779 [==============================] - 0s 58us/step - loss: 0.6428 - mse: 0.6428 - val_loss: 1.5833 - val_mse: 1.5833\n",
      "Epoch 67/10000\n",
      "3779/3779 [==============================] - 0s 46us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5850 - val_mse: 1.5850\n",
      "Epoch 68/10000\n",
      "3779/3779 [==============================] - 0s 42us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5860 - val_mse: 1.5860\n",
      "Epoch 69/10000\n",
      "3779/3779 [==============================] - 0s 45us/step - loss: 0.6425 - mse: 0.6425 - val_loss: 1.5894 - val_mse: 1.5894\n",
      "Epoch 70/10000\n",
      "3779/3779 [==============================] - 0s 48us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5869 - val_mse: 1.5869\n",
      "Epoch 71/10000\n",
      "3779/3779 [==============================] - 0s 41us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5838 - val_mse: 1.5838\n",
      "Epoch 72/10000\n",
      "3779/3779 [==============================] - 0s 40us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5857 - val_mse: 1.5857\n",
      "Epoch 73/10000\n",
      "3779/3779 [==============================] - 0s 37us/step - loss: 0.6427 - mse: 0.6427 - val_loss: 1.5865 - val_mse: 1.5865\n",
      "Epoch 74/10000\n",
      "3779/3779 [==============================] - 0s 35us/step - loss: 0.6426 - mse: 0.6426 - val_loss: 1.5847 - val_mse: 1.5847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13aac0cd0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo=Sequential()\n",
    "modelo.add(Conv1D(padding='same',filters=5,kernel_size=10\n",
    "                  ,input_shape=(1,12)\n",
    "                  #,strides=2\n",
    "                 ))\n",
    "modelo.add=MaxPooling1D(100)\n",
    "#modelo.add=Conv1D(filters=10,kernel_size=8,padding='same')\n",
    "#modelo.add=MaxPooling1D(20)\n",
    "#modelo.add=BatchNormalization(axis=-1)\n",
    "#modelo.add=Flatten()\n",
    "modelo.add=Dense(30,activation='tanh')\n",
    "#modelo.add=Dense(10,activation='tanh')\n",
    "modelo.add=Dense(5,activation='linear')\n",
    "EarlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "modelo.compile(loss=keras.losses.mse,optimizer=sgd,metrics=['mse']) \n",
    "history=modelo.fit(x=carac,y=labels,batch_size=40,epochs=10000,verbose=1,validation_split=0.3,\n",
    "                   callbacks=[EarlyStopping]\n",
    "                  )\n",
    "plt.figure()\n",
    "plt.plot(np.sqrt(history.history['loss']))\n",
    "plt.plot(np.sqrt(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels0 es metalicidad\n",
    "\n",
    "labels1 edad media pesada en masa \n",
    "\n",
    "labels2 edad media pesada en luz\n",
    "\n",
    "labels3 HdA\n",
    "\n",
    "labels4 D4000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9061005844776393\n",
      "-0.9160571620865134\n",
      "3.3906358598478246\n",
      "-1.2537175457277216\n",
      "4.177340742630897\n",
      "-1.7166074677022694\n",
      "1.4237007211476143\n",
      "-4.226903996196858\n",
      "5.160011907631329\n",
      "-1.2266350147101979\n"
     ]
    }
   ],
   "source": [
    "maximo0=np.max(labels0)\n",
    "minimo0=np.min(labels0)\n",
    "maximo1=np.max(labels1)\n",
    "minimo1=np.min(labels1)\n",
    "maximo2=np.max(labels2)\n",
    "minimo2=np.min(labels2)\n",
    "maximo3=np.max(labels3)\n",
    "minimo3=np.min(labels3)\n",
    "maximo4=np.max(labels4)\n",
    "minimo4=np.min(labels4)\n",
    "print(maximo0)\n",
    "print(minimo0)\n",
    "print(maximo1)\n",
    "print(minimo1)\n",
    "print(maximo2)\n",
    "print(minimo2)\n",
    "print(maximo3)\n",
    "print(minimo3)\n",
    "print(maximo4)\n",
    "print(minimo4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aqui empiezo con Hyperas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a separar entre datos de entrenamiento y de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=carac[0:3800,0,0:12]\n",
    "X_test=carac[3800:5401,0,0:12]\n",
    "Y_train=labels[0:3800,0,0:5]\n",
    "Y_test=labels[3800:5400,0,0:5]\n",
    "Y0_train=labels[0:3800,0,0]\n",
    "Y0_test=labels[3800:5400,0,0]\n",
    "Y1_train=labels[0:3800,0,1]\n",
    "Y1_test=labels[3800:5400,0,1]\n",
    "Y2_train=labels[0:3800,0,2]\n",
    "Y2_test=labels[3800:5400,0,2]\n",
    "Y3_train=labels[0:3800,0,3]\n",
    "Y3_test=labels[3800:5400,0,3]\n",
    "Y4_train=labels[0:3800,0,4]\n",
    "Y4_test=labels[3800:5400,0,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es de la web de hyperas adaptado en mis datos pero aun no se muy bien como funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train,Y_train, X_test, Y_test):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(padding='same',filters=5\n",
    "                  ,kernel_size=({{choice([10,30,50,100])}})\n",
    "                  ,input_shape=(1,12)\n",
    "                  #,strides=2\n",
    "                 ))\n",
    "    model.add=Dense(5,activation='linear') #capa de salida\n",
    "    model.compile(loss=keras.losses.mse,optimizer=sgd,metrics=['mse']) \n",
    "    result=model.fit(X_train, Y_train\n",
    "             ,batch_size={{choice([40,60,80])}}\n",
    "             ,verbose=1\n",
    "             ,epochs=100\n",
    "             ,show_accuracy=True\n",
    "             ,validation_data=(X_test, Y_test)\n",
    "             )\n",
    "    score,acc = model.evaluate(X_test,Y_test,show_accuracy=True,verbose=0)\n",
    "    print('Test accuracy:',acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/Users/kike/Desktop/Master/TFM/<ipython-input-34-8b868cd8614c>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8b868cd8614c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                     \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                                     )\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kike/miniconda3/envs/py27/lib/python2.7/site-packages/hyperas/optim.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kike/miniconda3/envs/py27/lib/python2.7/site-packages/hyperas/optim.pyc\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_model_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hyperopt_model_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtemp_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./temp_model.py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mwrite_temp_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kike/miniconda3/envs/py27/lib/python2.7/site-packages/hyperas/optim.pyc\u001b[0m in \u001b[0;36mget_hyperopt_model_string\u001b[0;34m(model, data, functions, notebook_name, verbose, stack)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mcalling_script_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalling_script_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/Users/kike/Desktop/Master/TFM/<ipython-input-34-8b868cd8614c>'"
     ]
    }
   ],
   "source": [
    "#if __name__ == '__main__':\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                    data=data,\n",
    "                                    algo=tpe.suggest,\n",
    "                                    max_evals=5,\n",
    "                                    trials = Trials()\n",
    "                                    )\n",
    "X_train, Y_train, X_test, Y_test = data()\n",
    "print(\"Evaluation of best performing model:\")\n",
    "print(best_model.evaluate(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.sqrt(history.result['loss']))\n",
    "plt.plot(np.sqrt(history.result['val_loss']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
